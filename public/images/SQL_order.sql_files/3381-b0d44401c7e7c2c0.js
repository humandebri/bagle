!function(){try{var e="undefined"!=typeof window?window:"undefined"!=typeof global?global:"undefined"!=typeof self?self:{},n=(new e.Error).stack;n&&(e._sentryDebugIds=e._sentryDebugIds||{},e._sentryDebugIds[n]="43fa0e51-f60a-4c3b-87d4-686263a8a796",e._sentryDebugIdIdentifier="sentry-dbid-43fa0e51-f60a-4c3b-87d4-686263a8a796")}catch(e){}}();"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[3381],{2628:(e,n,t)=>{t.d(n,{gt:()=>b,kd:()=>p});var a=t(1438),s=t(32144),o=t(56947),r=t(5942),i=t(52213),l=t(28128),c=t(29127),d=t(77570),u=t(30053),m=t(30038);let p=5e4,g="\nCREATE OR REPLACE FUNCTION pg_temp.count_estimate(\n    query text\n) RETURNS integer LANGUAGE plpgsql AS $$\nDECLARE\n    plan jsonb;\nBEGIN\n    EXECUTE 'EXPLAIN (FORMAT JSON)' || query INTO plan;\n    RETURN plan->0->'Plan'->'Plan Rows';\nEND;\n$$;\n".trim(),_=e=>{var n,t,s;let{table:o,filters:r=[],enforceExactCount:i=!1}=e;if(!o)return"";if(i){let e=new a.Query().from(o.name,null!=(n=o.schema)?n:void 0).count();return r.filter(e=>e.value&&""!==e.value).forEach(n=>{let t=(0,m.b)(o,n);e=e.filter(n.column,n.operator,t)}),"select (".concat(e.toSql().slice(0,-1),"), false as is_estimate;")}{let e=new a.Query().from(o.name,null!=(t=o.schema)?t:void 0).select("*");r.filter(e=>e.value&&""!=e.value).forEach(n=>{let t=(0,m.b)(o,n);e=e.filter(n.column,n.operator,t)});let n=e.toSql(),i=new a.Query().from(o.name,null!=(s=o.schema)?s:void 0).count();r.filter(e=>e.value&&""!=e.value).forEach(e=>{let n=(0,m.b)(o,e);i=i.filter(e.column,e.operator,n)});let l=i.toSql().slice(0,-1);return"\n".concat(g,"\n\nwith approximation as (\n    select reltuples as estimate\n    from pg_class\n    where oid = ").concat(o.id,"\n)\nselect \n  case \n    when estimate = -1 then (select pg_temp.count_estimate('").concat(n.replaceAll("'","''"),"'))\n    when estimate > ").concat(p," then ").concat(r.length>0?"pg_temp.count_estimate('".concat(n.replaceAll("'","''"),"')"):"estimate","\n    else (").concat(l,")\n  end as count,\n  estimate = -1 or estimate > ").concat(p," as is_estimate\nfrom approximation;\n").trim()}};async function h(e,n){var t;let{queryClient:a,projectRef:s,connectionString:o,tableId:u,filters:m,roleImpersonationState:p,enforceExactCount:g}=e,h=await (0,i.Nj)(a,{projectRef:s,connectionString:o,id:u});if(!h)throw Error("Table not found");let b=(0,r.rH)(h),f=(0,l.Nf)(_({table:b,filters:m,enforceExactCount:g}),p),{result:y}=await (0,d.E)({projectRef:s,connectionString:o,sql:f,queryKey:["table-rows-count",b.id],isRoleImpersonationEnabled:(0,c._c)(null==p?void 0:p.role)},n);return{count:y[0].count,is_estimate:null!=(t=y[0].is_estimate)&&t}}let b=function(e){let{projectRef:n,connectionString:t,tableId:a,...r}=e,{enabled:i=!0,...l}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},c=(0,s.jE)();return(0,o.I)(u.j.tableRowsCount(n,{table:{id:a},...r}),e=>{let{signal:s}=e;return h({queryClient:c,projectRef:n,connectionString:t,tableId:a,...r},s)},{enabled:i&&void 0!==n&&void 0!==a,...l})}},21512:(e,n,t)=>{t.d(n,{Lh:()=>u,T_:()=>_});var a=t(32144),s=t(80251),o=t(73969),r=t(26616),i=t.n(r),l=t(77570),c=t(22096),d=t(68324);let u="pgmq_public",m=i()("\ncreate schema if not exists ".concat(u,";\ngrant usage on schema ").concat(u," to postgres, anon, authenticated, service_role;\n\ncreate or replace function ").concat(u,".pop(\n    queue_name text\n)\n  returns setof pgmq.message_record\n  language plpgsql\n  set search_path = ''\nas $$\nbegin\n    return query\n    select *\n    from pgmq.pop(\n        queue_name := queue_name\n    );\nend;\n$$;\n\ncomment on function ").concat(u,".pop(queue_name text) is 'Retrieves and locks the next message from the specified queue.';\n\n\ncreate or replace function ").concat(u,".send(\n    queue_name text,\n    message jsonb,\n    sleep_seconds integer default 0  -- renamed from 'delay'\n)\n  returns setof bigint\n  language plpgsql\n  set search_path = ''\nas $$\nbegin\n    return query\n    select *\n    from pgmq.send(\n        queue_name := queue_name,\n        msg := message,\n        delay := sleep_seconds\n    );\nend;\n$$;\n\ncomment on function ").concat(u,".send(queue_name text, message jsonb, sleep_seconds integer) is 'Sends a message to the specified queue, optionally delaying its availability by a number of seconds.';\n\n\ncreate or replace function ").concat(u,".send_batch(\n    queue_name text,\n    messages jsonb[],\n    sleep_seconds integer default 0  -- renamed from 'delay'\n)\n  returns setof bigint\n  language plpgsql\n  set search_path = ''\nas $$\nbegin\n    return query\n    select *\n    from pgmq.send_batch(\n        queue_name := queue_name,\n        msgs := messages,\n        delay := sleep_seconds\n    );\nend;\n$$;\n\ncomment on function ").concat(u,".send_batch(queue_name text, messages jsonb[], sleep_seconds integer) is 'Sends a batch of messages to the specified queue, optionally delaying their availability by a number of seconds.';\n\n\ncreate or replace function ").concat(u,".archive(\n    queue_name text,\n    message_id bigint\n)\n  returns boolean\n  language plpgsql\n  set search_path = ''\nas $$\nbegin\n    return\n    pgmq.archive(\n        queue_name := queue_name,\n        msg_id := message_id\n    );\nend;\n$$;\n\ncomment on function ").concat(u,".archive(queue_name text, message_id bigint) is 'Archives a message by moving it from the queue to a permanent archive.';\n\n\ncreate or replace function ").concat(u,".delete(\n    queue_name text,\n    message_id bigint\n)\n  returns boolean\n  language plpgsql\n  set search_path = ''\nas $$\nbegin\n    return\n    pgmq.delete(\n        queue_name := queue_name,\n        msg_id := message_id\n    );\nend;\n$$;\n\ncomment on function ").concat(u,".delete(queue_name text, message_id bigint) is 'Permanently deletes a message from the specified queue.';\n\ncreate or replace function ").concat(u,".read(\n    queue_name text,\n    sleep_seconds integer,\n    n integer\n)\n  returns setof pgmq.message_record\n  language plpgsql\n  set search_path = ''\nas $$\nbegin\n    return query\n    select *\n    from pgmq.read(\n        queue_name := queue_name,\n        vt := sleep_seconds,\n        qty := n\n    );\nend;\n$$;\n\ncomment on function ").concat(u,'.read(queue_name text, sleep_seconds integer, n integer) is \'Reads up to "n" messages from the specified queue with an optional "sleep_seconds" (visibility timeout).\';\n\n-- Grant execute permissions on wrapper functions to roles\ngrant execute on function ').concat(u,".pop(text) to postgres, service_role, anon, authenticated;\ngrant execute on function pgmq.pop(text) to postgres, service_role, anon, authenticated;\n\ngrant execute on function ").concat(u,".send(text, jsonb, integer) to postgres, service_role, anon, authenticated;\ngrant execute on function pgmq.send(text, jsonb, integer) to postgres, service_role, anon, authenticated;\n\ngrant execute on function ").concat(u,".send_batch(text, jsonb[], integer) to postgres, service_role, anon, authenticated;\ngrant execute on function pgmq.send_batch(text, jsonb[], integer) to postgres, service_role, anon, authenticated;\n\ngrant execute on function ").concat(u,".archive(text, bigint) to postgres, service_role, anon, authenticated;\ngrant execute on function pgmq.archive(text, bigint) to postgres, service_role, anon, authenticated;\n\ngrant execute on function ").concat(u,".delete(text, bigint) to postgres, service_role, anon, authenticated;\ngrant execute on function pgmq.delete(text, bigint) to postgres, service_role, anon, authenticated;\n\ngrant execute on function ").concat(u,".read(text, integer, integer) to postgres, service_role, anon, authenticated;\ngrant execute on function pgmq.read(text, integer, integer) to postgres, service_role, anon, authenticated;\n\n-- For the service role, we want full access\n-- Grant permissions on existing tables\ngrant all privileges on all tables in schema pgmq to postgres, service_role;\n\n-- Ensure service_role has permissions on future tables\nalter default privileges in schema pgmq grant all privileges on tables to postgres, service_role;\n\ngrant usage on schema pgmq to postgres, anon, authenticated, service_role;\n\n\n/*\n  Grant access to sequences to API roles by default. Existing table permissions\n  continue to enforce insert restrictions. This is necessary to accommodate the\n  on-backup hook that rebuild queue table primary keys to avoid a pg_dump segfault.\n  This can be removed once logical backups are completely retired.\n*/\ngrant usage, select, update\non all sequences in schema pgmq\nto anon, authenticated, service_role;\n\nalter default privileges in schema pgmq\ngrant usage, select, update\non sequences\nto anon, authenticated, service_role;\n")),p=i()("\n  drop function if exists \n    ".concat(u,".pop(queue_name text),\n    ").concat(u,".send(queue_name text, message jsonb, sleep_seconds integer),\n    ").concat(u,".send_batch(queue_name text, message jsonb[], sleep_seconds integer),\n    ").concat(u,".archive(queue_name text, message_id bigint),\n    ").concat(u,".delete(queue_name text, message_id bigint),\n    ").concat(u,".read(queue_name text, sleep integer, n integer)\n  ;\n\n  -- Revoke execute permissions on inner pgmq functions to roles (inverse of enabling)\n  do $$\n  begin\n      if exists (select 1 from pg_namespace where nspname = 'pgmq') then\n          -- Revoke privileges on the schema itself\n          revoke all on schema pgmq from anon, authenticated, service_role;\n          \n          -- Revoke default privileges for future objects\n          alter default privileges in schema pgmq revoke all on tables from anon, authenticated, service_role;\n          alter default privileges in schema pgmq revoke all on sequences from anon, authenticated, service_role;\n          alter default privileges in schema pgmq revoke all on functions from anon, authenticated, service_role;\n      end if;\n  end $$;\n\n  drop schema if exists ").concat(u,";\n"));async function g(e){let{projectRef:n,connectionString:t,enable:a}=e,{result:s}=await (0,l.E)({projectRef:n,connectionString:t,sql:a?m:p,queryKey:["toggle-queues-exposure"]});return s}let _=function(){let{onSuccess:e,onError:n,...t}=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},r=(0,a.jE)();return(0,s.n)(e=>g(e),{async onSuccess(n,t,a){let{projectRef:s}=t;await r.invalidateQueries(c.m.exposePostgrestStatus(s)),r.invalidateQueries(d.c.schemas(s)),await (null==e?void 0:e(n,t,a))},async onError(e,t,a){void 0===n?o.oR.error("Failed to toggle queue exposure via PostgREST: ".concat(e.message)):n(e,t,a)},...t})}},22096:(e,n,t)=>{t.d(n,{m:()=>a});let a={create:()=>["queues","create"],delete:e=>["queues",e,"delete"],purge:e=>["queues",e,"purge"],getMessagesInfinite:(e,n,t)=>["projects",e,"queue-messages",n,t].filter(Boolean),list:e=>["projects",e,"queues"],metrics:(e,n)=>["projects",e,"queue-metrics",n],exposePostgrestStatus:e=>["projects",e,"queue-expose-status"]}},24059:(e,n,t)=>{t.d(n,{A:()=>m});var a=t(80263),s=t(16477),o=t(99923),r=t(66452),i=t(63320),l=t.n(i),c=t(53239),d=t(16601);let u=(0,c.forwardRef)((e,n)=>{let{icon:t,title:i,description:u,url:m,urlLabel:p="Read more",defaultVisibility:g=!1,hideCollapse:_=!1,button:h,className:b="",block:f=!1}=e,[y,v]=(0,c.useState)(g);return(0,a.jsx)("div",{ref:n,role:"alert",className:"".concat(f?"block w-full":"","\n      block w-full rounded-md border bg-surface-300/25 py-3 ").concat(b),children:(0,a.jsxs)("div",{className:"flex flex-col px-4",children:[(0,a.jsxs)("div",{className:"flex items-center justify-between",children:[(0,a.jsxs)("div",{className:"flex w-full space-x-3 items-center",children:[t&&(0,a.jsx)("span",{className:"text-foreground-lighter",children:t}),(0,a.jsx)("div",{className:"flex-grow",children:(0,a.jsx)("h5",{className:"text-sm text-foreground",children:i})})]}),u&&!_?(0,a.jsx)("div",{className:"cursor-pointer text-foreground-lighter",onClick:()=>v(!y),children:y?(0,a.jsx)(s.A,{size:14,strokeWidth:1.5}):(0,a.jsx)(o.A,{size:14,strokeWidth:1.5})}):null]}),(u||m||h)&&(0,a.jsxs)("div",{className:"flex flex-col space-y-3 overflow-hidden transition-all ".concat(y?"mt-3":""),style:{maxHeight:500*!!y},children:[(0,a.jsx)("div",{className:"text-foreground-light text-sm",children:u}),m&&(0,a.jsx)("div",{children:(0,a.jsx)(d.$,{asChild:!0,type:"default",icon:(0,a.jsx)(r.A,{}),children:(0,a.jsx)(l(),{href:m,target:"_blank",rel:"noreferrer",children:p})})}),h&&(0,a.jsx)("div",{children:h})]})]})})});u.displayName="InformationBox";let m=u},24725:(e,n,t)=>{t.d(n,{i:()=>a});let a={tableEditor:(e,n)=>["projects",e,"table-editor",n]}},30038:(e,n,t)=>{t.d(n,{b:()=>o,j:()=>r});var a=t(80930),s=t(97195);function o(e,n){let t=e.columns.find(e=>e.name==n.column);if(t&&(0,a.n0)(t.format)){let e=Number(n.value);if(!Number.isNaN(e)&&!(e>Number.MAX_SAFE_INTEGER))return Number(n.value)}return n.value}function r(e){let{table:n}=e;if(!(0,s.KO)(n))return{error:{message:"Only table rows can be updated or deleted"}};let t=n.primary_keys;return t&&0!=t.length?{primaryKeys:t.map(e=>e.name)}:{error:{message:"Please add a primary key column to your table to update or delete rows"}}}},30053:(e,n,t)=>{t.d(n,{j:()=>a});let a={tableRows:function(e){let{table:n,roleImpersonationState:t,...a}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return["projects",e,"table-rows",null==n?void 0:n.id,"rows",{roleImpersonation:null==t?void 0:t.role,...a}]},tableRowsCount:function(e){let{table:n,...t}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return["projects",e,"table-rows",null==n?void 0:n.id,"count",t]},tableRowsAndCount:(e,n)=>["projects",e,"table-rows",n]}},30873:(e,n,t)=>{t.d(n,{li:()=>_,q3:()=>g,tv:()=>h});var a=t(80263),s=t(32144),o=t(52385),r=t(53239),i=t(5942),l=t(45969),c=t(52213),d=t(41518),u=t(29127),m=t(9594),p=t(45733);function g(e){let{queryClient:n,projectRef:t,connectionString:a,id:s,sorts:o,filters:r,roleImpersonationState:l}=e;return(0,c.Nj)(n,{projectRef:t,connectionString:a,id:s}).then(e=>{if(e){var c;let u=(0,i.rH)(e),{sorts:p=[],filters:g=[]}=null!=(c=(0,i.Tk)(t,e.name,e.schema))?c:{};(0,d.nk)(n,{projectRef:t,connectionString:a,tableId:s,sorts:null!=o?o:(0,i.FU)(u.name,p),filters:null!=r?r:(0,i.hl)(g),page:1,limit:m.to,roleImpersonationState:l})}})}function _(){let e=(0,o.useRouter)(),n=(0,s.jE)(),{project:t}=(0,l.Om)(),a=(0,u.RY)();return(0,r.useCallback)(s=>{let{id:o,filters:r,sorts:i}=s,l=o?Number(o):void 0;!t||!l||isNaN(l)||(e.prefetch("/project/".concat(t.ref,"/editor/").concat(l)),g({queryClient:n,projectRef:t.ref,connectionString:t.connectionString,id:l,sorts:i,filters:r,roleImpersonationState:a}).catch(()=>{}))},[t,n,a,e])}function h(e){let{projectRef:n,id:t,sorts:s,filters:o,href:r,children:i,...l}=e,c=_();return(0,a.jsx)(p.A,{href:r||"/project/".concat(n,"/editor/").concat(t),prefetcher:()=>c({id:t,sorts:s,filters:o}),...l,"data-sentry-element":"PrefetchableLink","data-sentry-component":"EditorTablePageLink","data-sentry-source-file":"project.$ref.editor.$id.tsx",children:i})}},36365:(e,n,t)=>{t.d(n,{Q:()=>s,i:()=>a});let a=["auth","cron","extensions","information_schema","net","pgsodium","pgsodium_masks","pgbouncer","pgtle","realtime","storage","supabase_functions","supabase_migrations","vault","graphql","graphql_public",t(21512).Lh],s=a.filter(e=>"extensions"!==e)},41518:(e,n,t)=>{t.d(n,{HQ:()=>y,nk:()=>w,vs:()=>x});var a=t(32144),s=t(56947),o=t(1438),r=t(57210),i=t(82489),l=t(5942),c=t(52213),d=t(28128),u=t(29127),m=t(77570),p=t(30053),g=t(2628),_=t(30038);let h=e=>{var n;let t=e.columns.filter(e=>null==e?void 0:e.isPrimaryKey).map(e=>e.name);return 0!==t.length?t:[null==(n=e.columns[0])?void 0:n.name]};async function b(e){return new Promise(n=>setTimeout(n,e))}async function f(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:3,t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:500;for(let s=0;s<=n;s++)try{return await e()}catch(e){if((null==e?void 0:e.status)===429&&s<n){var a;let n=null==(a=e.headers)?void 0:a.get("retry-after"),o=n?1e3*parseInt(n):t*Math.pow(2,s);await b(o);continue}throw e}}let y=async e=>{var n;let{projectRef:t,connectionString:a,table:s,filters:r=[],sorts:l=[],roleImpersonationState:c,progressCallback:u}=e;if(i.pe&&!a)return console.error("Connection string is required"),[];let p=[],y=new o.Query,v=s.columns.filter(e=>{var n;return(null!=(n=null==e?void 0:e.enum)?n:[]).length>0&&"array"===e.dataType.toLowerCase()}).map(e=>'"'.concat(e.name,'"::text[]')),x=y.from(s.name,null!=(n=s.schema)?n:void 0).select(v.length>0?"*,".concat(v.join(",")):"*");if(r.filter(e=>e.value&&""!==e.value).forEach(e=>{let n=(0,_.b)(s,e);x=x.filter(e.column,e.operator,n)}),0===l.length&&s.estimateRowCount<=g.kd){let e=h(s);e.length>0&&e.forEach(e=>{x=x.order(s.name,e,!0,!0)})}else l.forEach(e=>{x=x.order(e.table,e.column,e.ascending,e.nullsFirst)});let w=-1;for(;;){let e=500*(w+=1),n=(w+1)*500-1,s=(0,d.Nf)(x.range(e,n).toSql(),c);try{let{result:e}=await f(async()=>(0,m.E)({projectRef:t,connectionString:a,sql:s}));if(p.push(...e),null==u||u(p.length),e.length<500)break;await b(500)}catch(e){throw Error("Error fetching table rows: ".concat(e instanceof Error?e.message:"Unknown error"))}}return p.filter(e=>1!==e[d.BO])};async function v(e,n){let{queryClient:t,projectRef:a,connectionString:s,tableId:o,roleImpersonationState:i,filters:p,sorts:g,limit:_,page:h}=e,b=await (0,c.Nj)(t,{projectRef:a,connectionString:s,id:o});if(!b)throw Error("Table not found");let f=(0,l.rH)(b),y=(0,d.Nf)((0,r.yG)({table:b,filters:p,sorts:g,limit:_,page:h}),i),{result:v}=await (0,m.E)({projectRef:a,connectionString:s,sql:y,queryKey:["table-rows",null==f?void 0:f.id],isRoleImpersonationEnabled:(0,u._c)(null==i?void 0:i.role)},n);return{rows:v.map((e,n)=>({idx:n,...e}))}}let x=function(e){let{projectRef:n,connectionString:t,tableId:o,...r}=e,{enabled:i=!0,...l}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{},c=(0,a.jE)();return(0,s.I)(p.j.tableRows(n,{table:{id:o},...r}),e=>{let{signal:a}=e;return v({queryClient:c,projectRef:n,connectionString:t,tableId:o,...r},a)},{enabled:i&&void 0!==n&&void 0!==o,...l})};function w(e,n){let{projectRef:t,connectionString:a,tableId:s,...o}=n;return e.fetchQuery(p.j.tableRows(t,{table:{id:s},...o}),n=>{let{signal:r}=n;return v({queryClient:e,projectRef:t,connectionString:a,tableId:s,...o},r)})}},52213:(e,n,t)=>{t.d(n,{Ap:()=>l,Nj:()=>d,Pk:()=>c});var a=t(56947),s=t(77570),o=t(24725),r=t(26616),i=t.n(r);async function l(e,n){var t,a;let{projectRef:o,connectionString:r,id:l}=e;if(!l)throw Error("id is required");let c=l?i()("\n    with base_table_info as (\n        select \n            c.oid::int8 as id,\n            nc.nspname as schema,\n            c.relname as name,\n            c.relkind,\n            c.relrowsecurity as rls_enabled,\n            c.relforcerowsecurity as rls_forced,\n            c.relreplident,\n            c.relowner,\n            obj_description(c.oid) as comment\n        from pg_class c\n        join pg_namespace nc on nc.oid = c.relnamespace\n        where c.oid = ".concat(l,"\n            and not pg_is_other_temp_schema(nc.oid)\n            and (\n                pg_has_role(c.relowner, 'USAGE')\n                or has_table_privilege(\n                    c.oid,\n                    'SELECT, INSERT, UPDATE, DELETE, TRUNCATE, REFERENCES, TRIGGER'\n                )\n                or has_any_column_privilege(c.oid, 'SELECT, INSERT, UPDATE, REFERENCES')\n            )\n    ),\n    table_stats as (\n        select \n            b.id,\n            case\n                when b.relreplident = 'd' then 'DEFAULT'\n                when b.relreplident = 'i' then 'INDEX'\n                when b.relreplident = 'f' then 'FULL'\n                else 'NOTHING'\n            end as replica_identity,\n            pg_total_relation_size(format('%I.%I', b.schema, b.name))::int8 as bytes,\n            pg_size_pretty(pg_total_relation_size(format('%I.%I', b.schema, b.name))) as size,\n            pg_stat_get_live_tuples(b.id) as live_rows_estimate,\n            pg_stat_get_dead_tuples(b.id) as dead_rows_estimate\n        from base_table_info b\n        where b.relkind in ('r', 'p')\n    ),\n    primary_keys as (\n        select \n            i.indrelid as table_id,\n            jsonb_agg(jsonb_build_object(\n                'schema', n.nspname,\n                'table_name', c.relname,\n                'table_id', i.indrelid::int8,\n                'name', a.attname\n            )) as primary_keys\n        from pg_index i\n        join pg_class c on i.indrelid = c.oid\n        join pg_attribute a on (a.attrelid = c.oid and a.attnum = any(i.indkey))\n        join pg_namespace n on c.relnamespace = n.oid\n        where i.indisprimary\n        group by i.indrelid\n    ),\n    relationships as (\n        select \n            c.conrelid as source_id,\n            c.confrelid as target_id,\n            jsonb_build_object(\n                'id', c.oid::int8,\n                'constraint_name', c.conname,\n                'deletion_action', c.confdeltype,\n                'update_action', c.confupdtype,\n                'source_schema', nsa.nspname,\n                'source_table_name', csa.relname,\n                'source_column_name', sa.attname,\n                'target_table_schema', nta.nspname,\n                'target_table_name', cta.relname,\n                'target_column_name', ta.attname\n            ) as rel_info\n        from pg_constraint c\n        join pg_class csa on c.conrelid = csa.oid\n        join pg_namespace nsa on csa.relnamespace = nsa.oid\n        join pg_attribute sa on (sa.attrelid = c.conrelid and sa.attnum = any(c.conkey))\n        join pg_class cta on c.confrelid = cta.oid\n        join pg_namespace nta on cta.relnamespace = nta.oid\n        join pg_attribute ta on (ta.attrelid = c.confrelid and ta.attnum = any(c.confkey))\n        where c.contype = 'f'\n    ),\n    columns as (\n        select \n            a.attrelid as table_id,\n            jsonb_agg(jsonb_build_object(\n                'id', (a.attrelid || '.' || a.attnum),\n                'table_id', c.oid::int8,\n                'schema', nc.nspname,\n                'table', c.relname,\n                'ordinal_position', a.attnum,\n                'name', a.attname,\n                'default_value', case \n                    when a.atthasdef then pg_get_expr(ad.adbin, ad.adrelid)\n                    else null\n                end,\n                'data_type', case \n                    when t.typtype = 'd' then \n                        case \n                            when bt.typelem <> 0::oid and bt.typlen = -1 then 'ARRAY'\n                            when nbt.nspname = 'pg_catalog' then format_type(t.typbasetype, null)\n                            else 'USER-DEFINED'\n                        end\n                    else \n                        case \n                            when t.typelem <> 0::oid and t.typlen = -1 then 'ARRAY'\n                            when nt.nspname = 'pg_catalog' then format_type(a.atttypid, null)\n                            else 'USER-DEFINED'\n                        end\n                end,\n                'format', case\n                    when t.typtype = 'e' then\n                        case\n                            when nt.nspname <> 'public' then concat(nt.nspname, '.', coalesce(bt.typname, t.typname))\n                            else coalesce(bt.typname, t.typname)\n                        end\n                    else\n                        coalesce(bt.typname, t.typname)\n                end,\n                'is_identity', a.attidentity in ('a', 'd'),\n                'identity_generation', case a.attidentity\n                    when 'a' then 'ALWAYS'\n                    when 'd' then 'BY DEFAULT'\n                    else null\n                end,\n                'is_generated', a.attgenerated in ('s'),\n                'is_nullable', not (a.attnotnull or t.typtype = 'd' and t.typnotnull),\n                'is_updatable', (\n                    b.relkind in ('r', 'p') or \n                    (b.relkind in ('v', 'f') and pg_column_is_updatable(b.id, a.attnum, false))\n                ),\n                'is_unique', uniques.table_id is not null,\n                'check', check_constraints.definition,\n                'comment', col_description(c.oid, a.attnum),\n                'enums', coalesce(\n                    (\n                        select jsonb_agg(e.enumlabel order by e.enumsortorder)\n                        from pg_catalog.pg_enum e\n                        where e.enumtypid = coalesce(bt.oid, t.oid)\n                            or e.enumtypid = coalesce(bt.typelem, t.typelem)\n                    ),\n                    '[]'::jsonb\n                )\n            ) order by a.attnum) as columns\n        from pg_attribute a\n        join base_table_info b on a.attrelid = b.id\n        join pg_class c on a.attrelid = c.oid\n        join pg_namespace nc on c.relnamespace = nc.oid\n        left join pg_attrdef ad on (a.attrelid = ad.adrelid and a.attnum = ad.adnum)\n        join pg_type t on a.atttypid = t.oid\n        join pg_namespace nt on t.typnamespace = nt.oid\n        left join pg_type bt on (t.typtype = 'd' and t.typbasetype = bt.oid)\n        left join pg_namespace nbt on bt.typnamespace = nbt.oid\n        left join (\n            select \n                conrelid as table_id,\n                conkey[1] as ordinal_position\n            from pg_catalog.pg_constraint\n            where contype = 'u' and cardinality(conkey) = 1\n            group by conrelid, conkey[1]\n        ) as uniques on uniques.table_id = a.attrelid and uniques.ordinal_position = a.attnum\n        left join (\n            select distinct on (conrelid, conkey[1])\n                conrelid as table_id,\n                conkey[1] as ordinal_position,\n                substring(\n                    pg_get_constraintdef(oid, true),\n                    8,\n                    length(pg_get_constraintdef(oid, true)) - 8\n                ) as definition\n            from pg_constraint\n            where contype = 'c' and cardinality(conkey) = 1\n            order by conrelid, conkey[1], oid asc\n        ) as check_constraints on check_constraints.table_id = a.attrelid \n                            and check_constraints.ordinal_position = a.attnum\n        where a.attnum > 0 \n        and not a.attisdropped\n        group by a.attrelid\n    )\n    select \n        case b.relkind\n            when 'r' then jsonb_build_object(\n                'entity_type', b.relkind,\n                'id', b.id,\n                'schema', b.schema,\n                'name', b.name,\n                'rls_enabled', b.rls_enabled,\n                'rls_forced', b.rls_forced,\n                'replica_identity', ts.replica_identity,\n                'bytes', ts.bytes,\n                'size', ts.size,\n                'live_rows_estimate', ts.live_rows_estimate,\n                'dead_rows_estimate', ts.dead_rows_estimate,\n                'comment', b.comment,\n                'primary_keys', coalesce(pk.primary_keys, '[]'::jsonb),\n                'relationships', coalesce(\n                    (select jsonb_agg(r.rel_info)\n                    from relationships r\n                    where r.source_id = b.id or r.target_id = b.id), \n                    '[]'::jsonb\n                ),\n                'columns', coalesce(c.columns, '[]'::jsonb)\n            )\n            when 'p' then jsonb_build_object(\n                'entity_type', b.relkind,\n                'id', b.id,\n                'schema', b.schema,\n                'name', b.name,\n                'rls_enabled', b.rls_enabled,\n                'rls_forced', b.rls_forced,\n                'replica_identity', ts.replica_identity,\n                'bytes', ts.bytes,\n                'size', ts.size,\n                'live_rows_estimate', ts.live_rows_estimate,\n                'dead_rows_estimate', ts.dead_rows_estimate,\n                'comment', b.comment,\n                'primary_keys', coalesce(pk.primary_keys, '[]'::jsonb),\n                'relationships', coalesce(\n                    (select jsonb_agg(r.rel_info)\n                    from relationships r\n                    where r.source_id = b.id or r.target_id = b.id), \n                    '[]'::jsonb\n                ),\n                'columns', coalesce(c.columns, '[]'::jsonb)\n            )\n            when 'v' then jsonb_build_object(\n                'entity_type', b.relkind,\n                'id', b.id,\n                'schema', b.schema,\n                'name', b.name,\n                'is_updatable', (pg_relation_is_updatable(b.id, false) & 20) = 20,\n                'comment', b.comment,\n                'columns', coalesce(c.columns, '[]'::jsonb)\n            )\n            when 'm' then jsonb_build_object(\n                'entity_type', b.relkind,\n                'id', b.id,\n                'schema', b.schema,\n                'name', b.name,\n                'is_populated', true,\n                'comment', b.comment,\n                'columns', coalesce(c.columns, '[]'::jsonb)\n            )\n            when 'f' then jsonb_build_object(\n                'entity_type', b.relkind,\n                'id', b.id,\n                'schema', b.schema,\n                'name', b.name,\n                'comment', b.comment,\n                'columns', coalesce(c.columns, '[]'::jsonb)\n            )\n        end as entity\n    from base_table_info b\n    left join table_stats ts on b.id = ts.id\n    left join primary_keys pk on b.id = pk.table_id\n    left join columns c on b.id = c.table_id;\n  ")):"",{result:d}=await (0,s.E)({projectRef:o,connectionString:r,sql:c,queryKey:["table-editor",l]},n);return null!=(a=null==(t=d[0])?void 0:t.entity)?a:void 0}let c=function(e){let{projectRef:n,connectionString:t,id:s}=e,{enabled:r=!0,...i}=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};return(0,a.I)(o.i.tableEditor(n,s),e=>{let{signal:a}=e;return l({projectRef:n,connectionString:t,id:s},a)},{enabled:r&&void 0!==n&&void 0!==s&&!isNaN(s),refetchOnWindowFocus:!1,refetchOnMount:!1,staleTime:3e5,...i})};function d(e,n){let{projectRef:t,connectionString:a,id:s}=n;return e.fetchQuery(o.i.tableEditor(t,s),e=>{let{signal:n}=e;return l({projectRef:t,connectionString:a,id:s},n)})}},57210:(e,n,t)=>{t.d(n,{BA:()=>r,SF:()=>o,yG:()=>p});var a=t(47354),s=t(36222);let o=10240,r=50,i=["text","varchar","char","character varying","character"],l=["json","jsonb"],c=new Set(l),d=new Set([...i,...l,"bytea","xml","hstore","clob","vector","geometry","geography","tsvector","tsquery","daterange","tsrange","tstzrange","numrange","int4range","int8range","cube","ltree","lquery","jsonpath","citext"]),u=e=>{var n;let t=null==(n=e.primary_keys)?void 0:n.map(e=>e.name);return t&&t.length>0?t:e.columns&&e.columns.length>0?[e.columns[0].name]:[]},m=e=>d.has(e.toLowerCase()),p=e=>{let{table:n,filters:t=[],sorts:l=[],page:d,limit:p,maxCharacters:g=o,maxArraySize:_=r}=e;if(!n||!n.columns)return"";let h=new s.X().from(n.name,n.schema).select();t.forEach(e=>{var t;let a=null==(t=n.columns)?void 0:t.find(n=>n.name===e.column),s=!a||i.includes(a.format);h=h.filter(e.column,e.operator,s||""!==e.value?e.value:null)});let b=n.live_rows_estimate||0;if(0===l.length&&b<=1e5&&n.columns.length>0){let e=u(n);e.length>0&&e.forEach(e=>{h=h.order(n.name,e,!0,!0)})}else l.forEach(e=>{h=h.order(e.table,e.column,e.ascending,e.nullsFirst)});let{from:f,to:y}=function(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:100,t=e?e*n:0;return{from:t,to:e?t+n-1:n-1}}((null!=d?d:1)-1,p),v="with _base_query as (".concat(h.range(f,y).toSql({isCTE:!1,isFinal:!1}),")"),x=n.columns.sort((e,n)=>e.ordinal_position-n.ordinal_position).map(e=>({name:e.name,format:e.format.toLowerCase()})),w=n.columns.filter(e=>m(e.format)).map(e=>e.name),j=x.map(e=>{let{name:n}=e,t=(0,a.bD)(n);return w.includes(n)?"case\n        when octet_length(".concat(t,"::text) > ").concat(g," \n        then left(").concat(t,"::text, ").concat(g,") || '...'\n        else ").concat(t,"::text\n      end as ").concat(t):t});n.columns.filter(e=>"array"===e.data_type.toLowerCase()).map(e=>({name:e.name,format:e.format.toLowerCase().slice(1)})).forEach(e=>{let{name:n,format:t}=e,s=j.findIndex(e=>e===(0,a.bD)(n)),o=c.has(t)?"".concat(t,"[]"):"text[]",r="text[]"===o?"array['...']":"array['{\"truncated\": true}'::json]";s>=0&&(j[s]="\n        case \n          when octet_length(".concat((0,a.bD)(n),"::text) > ").concat(g," \n          then (select array_cat(").concat((0,a.bD)(n),"[1:").concat(_,"]::").concat(o,", ").concat(r,"::").concat(o,"))::").concat(o,"\n          else ").concat((0,a.bD)(n),"::").concat(o,"\n        end\n      "))});let q=j.join(","),E=new s.X().from("_base_query").select(q);return"".concat(v,"\n  ").concat(E.toSql({isCTE:!0,isFinal:!0}))}},80930:(e,n,t)=>{t.d(n,{AM:()=>w,I:()=>f,KV:()=>g,Lj:()=>r,_c:()=>m,ao:()=>l,cx:()=>d,e2:()=>E,hB:()=>h,n0:()=>s,th:()=>v,yB:()=>q});let a=["smallint","integer","bigint","decimal","numeric","real","double precision","serial","bigserial","int2","int4","int8","float4","float8","smallserial","serial2","serial4","serial8"];function s(e){return a.indexOf(e.toLowerCase())>-1}let o=["json","jsonb","array"];function r(e){return o.indexOf(e.toLowerCase())>-1}let i=["array"];function l(e){return i.indexOf(e.toLowerCase())>-1}let c=["uuid","text","character varying"];function d(e){return c.indexOf(e.toLowerCase())>-1}let u=["citext"];function m(e){return u.indexOf(e.toLowerCase())>-1}let p=["timestamp","timestamptz"];function g(e){return p.indexOf(e.toLowerCase())>-1}let _=["date"];function h(e){return _.indexOf(e.toLowerCase())>-1}let b=["time","timetz"];function f(e){return b.indexOf(e.toLowerCase())>-1}let y=["boolean","bool"];function v(e){return y.indexOf(e.toLowerCase())>-1}let x=["user-defined"];function w(e){return x.indexOf(e.toLowerCase())>-1}let j=["bytea"];function q(e){return j.indexOf(e.toLowerCase())>-1}function E(e){var n;let{targetTableSchema:t,targetTableName:a,targetColumnName:s}=null!=(n=null==e?void 0:e.foreignKey)?n:{};return!!t&&!!a&&!!s}},98303:(e,n,t)=>{t.d(n,{A:()=>u,b:()=>d});var a=t(80263),s=t(53239),o=t(55335),r=t(16601),i=t(98883),l=t(36365),c=t(65325);let d=e=>{let{visible:n,onClose:t}=e;return(0,a.jsx)(o.A,{size:"medium",visible:n,header:"Schemas managed by Supabase",customFooter:(0,a.jsx)("div",{className:"flex items-center justify-end space-x-2",children:(0,a.jsx)(r.$,{type:"default",onClick:()=>t(),children:"Understood"})}),onCancel:()=>t(),"data-sentry-element":"Modal","data-sentry-component":"ProtectedSchemaModal","data-sentry-source-file":"ProtectedSchemaWarning.tsx",children:(0,a.jsxs)(o.A.Content,{className:"space-y-2","data-sentry-element":"unknown","data-sentry-source-file":"ProtectedSchemaWarning.tsx",children:[(0,a.jsx)("p",{className:"text-sm",children:"The following schemas are managed by Supabase and are currently protected from write access through the dashboard."}),(0,a.jsx)("div",{className:"flex flex-wrap gap-1",children:l.i.map(e=>(0,a.jsx)("code",{className:"text-xs",children:e},e))}),(0,a.jsx)("p",{className:"text-sm !mt-4",children:"These schemas are critical to the functionality of your Supabase project and hence we highly recommend not altering them."}),(0,a.jsx)("p",{className:"text-sm",children:"You can, however, still interact with those schemas through the SQL Editor although we advise you only do so if you know what you are doing."})]})})},u=e=>{let{schema:n,entity:t}=e,[o,l]=(0,s.useState)(!1);return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(i.Fc,{"data-sentry-element":"Alert_Shadcn_","data-sentry-source-file":"ProtectedSchemaWarning.tsx",children:[(0,a.jsx)(c.A,{strokeWidth:2,"data-sentry-element":"AlertCircle","data-sentry-source-file":"ProtectedSchemaWarning.tsx"}),(0,a.jsxs)(i.XL,{"data-sentry-element":"AlertTitle_Shadcn_","data-sentry-source-file":"ProtectedSchemaWarning.tsx",children:["Currently viewing ",t," from a protected schema"]}),(0,a.jsxs)(i.TN,{"data-sentry-element":"AlertDescription_Shadcn_","data-sentry-source-file":"ProtectedSchemaWarning.tsx",children:[(0,a.jsxs)("p",{className:"mb-2",children:["The ",(0,a.jsx)("code",{className:"text-xs",children:n})," schema is managed by Supabase and is read-only through the dashboard."]}),(0,a.jsx)(r.$,{type:"default",size:"tiny",onClick:()=>l(!0),"data-sentry-element":"Button","data-sentry-source-file":"ProtectedSchemaWarning.tsx",children:"Learn more"})]})]}),(0,a.jsx)(d,{visible:o,onClose:()=>l(!1),"data-sentry-element":"ProtectedSchemaModal","data-sentry-source-file":"ProtectedSchemaWarning.tsx"})]})}}}]);